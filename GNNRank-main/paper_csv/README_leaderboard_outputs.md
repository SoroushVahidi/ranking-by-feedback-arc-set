# Leaderboard and audit outputs (manuscript)

These CSVs are produced by **`tools/build_leaderboard_csvs.py`** (run from repo root: `python tools/build_leaderboard_csvs.py`). They do **not** use any oracle at the row level; oracle values are only in the envelope file and are explicitly labeled.

## Output files

| File | Description |
|------|-------------|
| **leaderboard_per_method.csv** | Per-method leaderboard (no oracle): one row per (dataset, method, config). All OURS variants, all classical baselines, and each GNN variant separately. |
| **leaderboard_oracle_envelopes.csv** | Per-dataset oracle envelopes: `best_classical_*` and `best_gnn_*` with which method/variant achieved each. |
| **leaderboard_compute_matched.csv** | Same schema as per-method but **filtered to runs with runtime_sec ≤ 1800**. Use for compute-fair comparison. |
| **leaderboard_compute_matched_coverage.csv** | Per-method counts: n_valid_upset_simple, n_valid_runtime, n_timeout, n_within_time_budget. |
| **missingness_audit.csv** | Per-method: n_datasets_with_valid_metrics, n_valid_runtime, n_timeouts; **finance_like_exclusions** explicitly recorded (e.g. `finance:no_data`, `finance:timeout`). |

## How to cite in the manuscript

- **Main tables (no oracle):** “Per-method results are in `leaderboard_per_method.csv`; each row is a (dataset, method) or (dataset, method, config) for OURS variants, classical baselines, and GNN variants.”
- **Oracle comparisons:** “Best classical and best GNN per dataset (min upset_simple) are in `leaderboard_oracle_envelopes.csv`, with the method that achieved each value.”
- **Compute-matched:** “For a shared time budget of 1800s, we report results in `leaderboard_compute_matched.csv`; coverage (including timeouts and Finance exclusions) is in `leaderboard_compute_matched_coverage.csv` and `missingness_audit.csv`.”
- **Missingness:** “We do not silently drop datasets: `missingness_audit.csv` records per-method valid metrics, valid runtime, timeouts, and Finance-like exclusions.”

## Dependencies

- **paper_csv/results_from_result_arrays.csv** (generated by `tools/build_results_table_from_result_arrays.py`).
- **full_833614_metrics_best.csv** (optional fallback for datasets/methods not in result_arrays).
